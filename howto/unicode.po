# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2001-2024, Python Software Foundation
# This file is distributed under the same license as the Python package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
# Translators:
# tomo, 2021
# Shin Saito, 2021
# Takanori Suzuki <takanori@takanory.net>, 2023
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Python 3.13\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-08-31 10:59+0000\n"
"PO-Revision-Date: 2021-06-28 00:53+0000\n"
"Last-Translator: Takanori Suzuki <takanori@takanory.net>, 2023\n"
"Language-Team: Japanese (https://app.transifex.com/python-doc/teams/5390/"
"ja/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: ja\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../howto/unicode.rst:5
msgid "Unicode HOWTO"
msgstr "Unicode HOWTO"

#: ../../howto/unicode.rst:0
msgid "Release"
msgstr "ãƒªãƒªãƒ¼ã‚¹"

#: ../../howto/unicode.rst:7
msgid "1.12"
msgstr "1.12"

#: ../../howto/unicode.rst:9
msgid ""
"This HOWTO discusses Python's support for the Unicode specification for "
"representing textual data, and explains various problems that people "
"commonly encounter when trying to work with Unicode."
msgstr ""
"ã“ã® HOWTO æ–‡æ›¸ã¯ã€æ–‡å­—ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¾ã®ãŸã‚ã® Unicode ä»•æ§˜ã® Python ã«ãŠã‘ã‚‹ã‚µ"
"ãƒãƒ¼ãƒˆã«ã¤ã„ã¦è«–ã˜ã€ã•ã‚‰ã« Unicode ã‚’ä½¿ãŠã†ã¨ã„ã†ã¨ãã«ã‚ˆãå‡ºå–°ã‚ã™å¤šãã®å•é¡Œ"
"ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:15
msgid "Introduction to Unicode"
msgstr "Unicode å…¥é–€"

#: ../../howto/unicode.rst:18
msgid "Definitions"
msgstr "å®šç¾©"

#: ../../howto/unicode.rst:20
msgid ""
"Today's programs need to be able to handle a wide variety of characters.  "
"Applications are often internationalized to display messages and output in a "
"variety of user-selectable languages; the same program might need to output "
"an error message in English, French, Japanese, Hebrew, or Russian.  Web "
"content can be written in any of these languages and can also include a "
"variety of emoji symbols. Python's string type uses the Unicode Standard for "
"representing characters, which lets Python programs work with all these "
"different possible characters."
msgstr ""
"ä»Šæ—¥ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯åºƒç¯„å›²ã®æ–‡å­—ã‚’æ‰±ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n"
"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯å›½éš›åŒ–ã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸ã¹ã‚‹æ§˜ã€…ãªè¨€èªã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„å‡ºåŠ›ã‚’"
"è¡¨ç¤ºã—ã¾ã™; åŒã˜ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒã€è‹±èªã€ãƒ•ãƒ©ãƒ³ã‚¹èªã€æ—¥æœ¬èªã€ãƒ˜ãƒ–ãƒ©ã‚¤èªã€ãƒ­ã‚·ã‚¢èª"
"ã§ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n"
"Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã©ã‚“ãªè¨€èªã§ã‚‚æ›¸ã‹ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã—ã€æ§˜ã€…ãªçµµæ–‡å­—ãŒå«ã¾ã‚Œ"
"ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚\n"
"Python ã®æ–‡å­—åˆ—å‹ã¯æ–‡å­—è¡¨ç¾ã®ãŸã‚ã® Unicode æ¨™æº–ã‚’ä½¿ã£ã¦ã„ã¦ã€ Python ãƒ—ãƒ­ã‚°"
"ãƒ©ãƒ ã¯æœ‰ã‚Šå¾—ã‚‹æ§˜ã€…ãªæ–‡å­—ã‚’å…¨ã¦æ‰±ãˆã¾ã™ã€‚"

#: ../../howto/unicode.rst:30
msgid ""
"Unicode (https://www.unicode.org/) is a specification that aims to list "
"every character used by human languages and give each character its own "
"unique code.  The Unicode specifications are continually revised and updated "
"to add new languages and symbols."
msgstr ""
"Unicode (https://www.unicode.org/) ã¯ã€äººé¡ã®è¨€èªã§ä½¿ã‚ã‚Œã‚‹å…¨ã¦ã®æ–‡å­—ã‚’åˆ—æŒ™"
"ã—ã€ãã‚Œãã‚Œã®æ–‡å­—è‡ªèº«ã®ä¸€æ„ãªç¬¦å·ã‚’ä¸ãˆã‚‹ã®ã‚’ç›®çš„ã¨ã—ãŸä»•æ§˜ã§ã™ã€‚\n"
"Unicode ä»•æ§˜ã¯ç¶™ç¶šçš„ã«æ”¹è¨‚ã•ã‚Œã€æ–°ã—ã„è¨€èªã‚„è¨˜å·ã‚’è¿½åŠ ã™ã‚‹æ›´æ–°ãŒãªã•ã‚Œã¦ã„ã¾"
"ã™ã€‚"

#: ../../howto/unicode.rst:35
msgid ""
"A **character** is the smallest possible component of a text.  'A', 'B', "
"'C', etc., are all different characters.  So are 'Ãˆ' and 'Ã'.  Characters "
"vary depending on the language or context you're talking about.  For "
"example, there's a character for \"Roman Numeral One\", 'â… ', that's separate "
"from the uppercase letter 'I'.  They'll usually look the same, but these are "
"two different characters that have different meanings."
msgstr ""
"**æ–‡å­—** ã¯æ–‡ç« ã®æœ€å°ã®æ§‹æˆè¦ç´ ã§ã™ã€‚\n"
"'A', 'B', 'C' ãªã©ã¯å…¨ã¦ç•°ãªã‚‹æ–‡å­—ã§ã™ã€‚\n"
"'Ãˆ' ã¨ 'Ã' ã‚‚åŒæ§˜ã«ç•°ãªã‚‹æ–‡å­—ã§ã™ã€‚\n"
"æ–‡å­—ã¯ã€è©±ã—ã¦ã„ã‚‹è¨€èªã‚„æ–‡è„ˆã«ã‚ˆã£ã¦å¤‰ã‚ã£ã¦ãã¾ã™ã€‚\n"
"ä¾‹ãˆã°ã€ã€Œãƒ­ãƒ¼ãƒæ•°å­—ã® 1ã€ã¨ã„ã†æ–‡å­— 'â… ' ã¯å¤§æ–‡å­—ã® 'I' ã¨ã¯åˆ¥ã®æ–‡å­—ã§ã™ã€‚\n"
"ä¸¡è€…ã¯é€šå¸¸ã¯åŒã˜ã«è¦‹ãˆã¾ã™ãŒã€ç•°ãªã‚‹æ„å‘³ã‚’æŒã¤åˆ¥ã€…ã®2ã¤ã®æ–‡å­—ã§ã™ã€‚"

#: ../../howto/unicode.rst:42
msgid ""
"The Unicode standard describes how characters are represented by **code "
"points**.  A code point value is an integer in the range 0 to 0x10FFFF "
"(about 1.1 million values, the `actual number assigned <https://www.unicode."
"org/versions/latest/#Summary>`_ is less than that). In the standard and in "
"this document, a code point is written using the notation ``U+265E`` to mean "
"the character with value ``0x265e`` (9,822 in decimal)."
msgstr ""

#: ../../howto/unicode.rst:50
msgid ""
"The Unicode standard contains a lot of tables listing characters and their "
"corresponding code points:"
msgstr ""
"Unicode æ¨™æº–ã¯ã€æ–‡å­—ã¨ãã‚Œã«å¯¾å¿œã™ã‚‹ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’åˆ—æŒ™ã—ãŸå¤šãã®è¡¨ã‚’å«ã‚“ã§"
"ã„ã¾ã™:"

#: ../../howto/unicode.rst:53
msgid ""
"0061    'a'; LATIN SMALL LETTER A\n"
"0062    'b'; LATIN SMALL LETTER B\n"
"0063    'c'; LATIN SMALL LETTER C\n"
"...\n"
"007B    '{'; LEFT CURLY BRACKET\n"
"...\n"
"2167    'â…§'; ROMAN NUMERAL EIGHT\n"
"2168    'â…¨'; ROMAN NUMERAL NINE\n"
"...\n"
"265E    'â™'; BLACK CHESS KNIGHT\n"
"265F    'â™Ÿ'; BLACK CHESS PAWN\n"
"...\n"
"1F600   'ğŸ˜€'; GRINNING FACE\n"
"1F609   'ğŸ˜‰'; WINKING FACE\n"
"..."
msgstr ""

#: ../../howto/unicode.rst:71
msgid ""
"Strictly, these definitions imply that it's meaningless to say 'this is "
"character ``U+265E``'.  ``U+265E`` is a code point, which represents some "
"particular character; in this case, it represents the character 'BLACK CHESS "
"KNIGHT', 'â™'.  In informal contexts, this distinction between code points "
"and characters will sometimes be forgotten."
msgstr ""
"å³å¯†ã«ã¯ã€ã“ã®å®šç¾©ã‹ã‚‰ã€Œã“ã‚Œã¯æ–‡å­— ``U+265E`` ã§ã™ã€ã¨è¨€ã†ã®ã¯æ„å‘³ã®ç„¡ã„ã“ã¨"
"ã ã¨åˆ†ã‹ã‚Šã¾ã™ã€‚``U+265E`` ã¯ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ã‚ã‚Šã€ãã‚Œã¯ã‚ã‚‹ç‰¹å®šã®æ–‡å­—ã‚’è¡¨ã—"
"ã¦ã„ã‚‹ã®ã§ã™; ã“ã®å ´åˆã§ã¯ã€ 'BLACK CHESS KNIGHT', 'â™' ã¨ã„ã†æ–‡å­—ã‚’è¡¨ã—ã¦ã„ã¾"
"ã™ã€‚\n"
"å½¢å¼ã°ã‚‰ãªã„æ–‡è„ˆã§ã¯ã€ã“ã®ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨æ–‡å­—ã®åŒºåˆ¥ã¯å¿˜ã‚Œå»ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚Š"
"ã¾ã™ã€‚"

#: ../../howto/unicode.rst:78
msgid ""
"A character is represented on a screen or on paper by a set of graphical "
"elements that's called a **glyph**.  The glyph for an uppercase A, for "
"example, is two diagonal strokes and a horizontal stroke, though the exact "
"details will depend on the font being used.  Most Python code doesn't need "
"to worry about glyphs; figuring out the correct glyph to display is "
"generally the job of a GUI toolkit or a terminal's font renderer."
msgstr ""
"æ–‡å­—ã¯ç”»é¢ã‚„ç´™é¢ä¸Šã§ã¯ **ã‚°ãƒªãƒ• (glyph)** ã¨å‘¼ã°ã‚Œã‚‹ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯è¦ç´ ã®çµ„ã§è¡¨"
"ç¤ºã•ã‚Œã¾ã™ã€‚å¤§æ–‡å­—ã® A ã®ã‚°ãƒªãƒ•ã¯ä¾‹ãˆã°ã€å³å¯†ãªå½¢ã¯ä½¿ã£ã¦ã„ã‚‹ãƒ•ã‚©ãƒ³ãƒˆã«ã‚ˆã£ã¦"
"ç•°ãªã‚Šã¾ã™ãŒã€æ–œã‚ã®ç·šã¨æ°´å¹³ã®ç·šã§ã™ã€‚ãŸã„ã¦ã„ã® Python ã‚³ãƒ¼ãƒ‰ã§ã¯ã‚°ãƒªãƒ•ã®å¿ƒ"
"é…ã‚’ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“; ä¸€èˆ¬çš„ã«ã¯è¡¨ç¤ºã™ã‚‹æ­£ã—ã„ã‚°ãƒªãƒ•ã‚’è¦‹ä»˜ã‘ã‚‹ã“ã¨ã¯ GUI "
"toolkit ã‚„ç«¯æœ«ã®ãƒ•ã‚©ãƒ³ãƒˆãƒ¬ãƒ³ãƒ€ãƒ©ãƒ¼ã®ä»•äº‹ã§ã™ã€‚"

#: ../../howto/unicode.rst:87
msgid "Encodings"
msgstr "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"

#: ../../howto/unicode.rst:89
msgid ""
"To summarize the previous section: a Unicode string is a sequence of code "
"points, which are numbers from 0 through ``0x10FFFF`` (1,114,111 decimal).  "
"This sequence of code points needs to be represented in memory as a set of "
"**code units**, and **code units** are then mapped to 8-bit bytes.  The "
"rules for translating a Unicode string into a sequence of bytes are called a "
"**character encoding**, or just an **encoding**."
msgstr ""
"å‰ã®ç¯€ã‚’ã¾ã¨ã‚ã‚‹ã¨: Unicode æ–‡å­—åˆ—ã¯ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®åˆ—ã§ã‚ã‚Šã€ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"
"ã¨ã¯ 0 ã‹ã‚‰ ``0x10FFFF`` (10 é€²è¡¨è¨˜ã§ 1,114,111) ã¾ã§ã®æ•°å€¤ã§ã™ã€‚ã“ã®ã‚³ãƒ¼ãƒ‰ãƒ"
"ã‚¤ãƒ³ãƒˆåˆ—ã¯ãƒ¡ãƒ¢ãƒªä¸Šã§ã¯ **ã‚³ãƒ¼ãƒ‰ãƒ¦ãƒ‹ãƒƒãƒˆ** åˆ—ã¨ã—ã¦è¡¨ã•ã‚Œã€ãã® **ã‚³ãƒ¼ãƒ‰ãƒ¦ãƒ‹ãƒƒ"
"ãƒˆ** åˆ—ã¯ 8-bit ã®ãƒã‚¤ãƒˆåˆ—ã«ãƒãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚Unicode æ–‡å­—åˆ—ã‚’ãƒã‚¤ãƒˆåˆ—ã¨ã—ã¦ç¿»"
"è¨³ã™ã‚‹è¦å‰‡ã‚’ **æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°** ã¾ãŸã¯å˜ã« **ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°** ã¨å‘¼ã³"
"ã¾ã™ã€‚"

#: ../../howto/unicode.rst:97
msgid ""
"The first encoding you might think of is using 32-bit integers as the code "
"unit, and then using the CPU's representation of 32-bit integers. In this "
"representation, the string \"Python\" might look like this:"
msgstr ""

#: ../../howto/unicode.rst:101
msgid ""
"   P           y           t           h           o           n\n"
"0x50 00 00 00 79 00 00 00 74 00 00 00 68 00 00 00 6f 00 00 00 6e 00 00 00\n"
"   0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23"
msgstr ""

#: ../../howto/unicode.rst:107
msgid ""
"This representation is straightforward but using it presents a number of "
"problems."
msgstr ""
"ã“ã®è¡¨ç¾ã¯ç›´æ¥çš„ã§ã‚ã‹ã‚Šã‚„ã™ã„æ–¹æ³•ã§ã™ãŒã€ã“ã®è¡¨ç¾ã‚’ä½¿ã†ã«ã¯ã„ãã¤ã‹ã®å•é¡ŒãŒ"
"ã‚ã‚Šã¾ã™ã€‚"

#: ../../howto/unicode.rst:110
msgid "It's not portable; different processors order the bytes differently."
msgstr ""
"å¯æ¬æ€§ãŒãªã„; ãƒ—ãƒ­ã‚»ãƒƒã‚µãŒç•°ãªã‚‹ã¨ãƒã‚¤ãƒˆã®é †åºã¥ã‘ã‚‚å¤‰ã‚ã£ã¦ã—ã¾ã„ã¾ã™ã€‚"

#: ../../howto/unicode.rst:112
msgid ""
"It's very wasteful of space.  In most texts, the majority of the code points "
"are less than 127, or less than 255, so a lot of space is occupied by "
"``0x00`` bytes.  The above string takes 24 bytes compared to the 6 bytes "
"needed for an ASCII representation.  Increased RAM usage doesn't matter too "
"much (desktop computers have gigabytes of RAM, and strings aren't usually "
"that large), but expanding our usage of disk and network bandwidth by a "
"factor of 4 is intolerable."
msgstr ""
"ç„¡é§„ãªé ˜åŸŸãŒå¤šã„ã§ã™ã€‚å¤šãã®æ–‡æ›¸ã§ã¯ã€ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ 127 æœªæº€ã‚‚ã—ãã¯ 255 "
"æœªæº€ãŒå¤šæ•°æ´¾ã‚’å ã‚ã€ãã®ãŸã‚å¤šãã®é ˜åŸŸãŒ ``0x00`` ã¨ã„ã†ãƒã‚¤ãƒˆã§åŸ‹ã‚å°½ãã•ã‚Œ"
"ã¾ã™ã€‚ä¸Šã®æ–‡å­—åˆ—ã¯ã€ASCII è¡¨ç¾ã§ã¯ 6 ãƒã‚¤ãƒˆãªã®ã«å¯¾ã—ã€24 ãƒã‚¤ãƒˆã®ã‚µã‚¤ã‚ºã«"
"ãªã£ã¦ã„ã¾ã™ã€‚RAM ã®ä½¿ç”¨é‡ãŒå¢—åŠ ã™ã‚‹ã®ã¯ãã‚Œã»ã©å•é¡Œã«ã¯ãªã‚Šã¾ã›ã‚“ (ãƒ‡ã‚¹ã‚¯"
"ãƒˆãƒƒãƒ—ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ã‚®ã‚¬ãƒã‚¤ãƒˆå˜ä½ã® RAM ã‚’æŒã£ã¦ãŠã‚Šã€é€šå¸¸ã€æ–‡å­—åˆ—ã¯ãã‚“ãªå¤§"
"ãã•ã«ã¯ãªã‚Šã¾ã›ã‚“) ãŒã€ãƒ‡ã‚£ã‚¹ã‚¯ã¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸãŒ 4 å€å¤šãä½¿ã‚ã‚Œã¦ã—ã¾ã†ã®"
"ã¯æˆ‘æ…¢ã§ãã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

#: ../../howto/unicode.rst:120
msgid ""
"It's not compatible with existing C functions such as ``strlen()``, so a new "
"family of wide string functions would need to be used."
msgstr ""
"``strlen()`` ã®ã‚ˆã†ãªç¾å­˜ã™ã‚‹ C é–¢æ•°ã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã›ã‚“ã€ãã®ãŸã‚ãƒ¯ã‚¤ãƒ‰æ–‡å­—"
"åˆ—é–¢æ•°ä¸€å¼ãŒæ–°ãŸã«å¿…è¦ã¨ãªã‚Šã¾ã™ã€‚"

#: ../../howto/unicode.rst:123
msgid ""
"Therefore this encoding isn't used very much, and people instead choose "
"other encodings that are more efficient and convenient, such as UTF-8."
msgstr ""

#: ../../howto/unicode.rst:126
msgid ""
"UTF-8 is one of the most commonly used encodings, and Python often defaults "
"to using it.  UTF stands for \"Unicode Transformation Format\", and the '8' "
"means that 8-bit values are used in the encoding.  (There are also UTF-16 "
"and UTF-32 encodings, but they are less frequently used than UTF-8.)  UTF-8 "
"uses the following rules:"
msgstr ""

#: ../../howto/unicode.rst:132
msgid ""
"If the code point is < 128, it's represented by the corresponding byte value."
msgstr "ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒ 128 æœªæº€ã ã£ãŸå ´åˆã€å¯¾å¿œã™ã‚‹ãƒã‚¤ãƒˆå€¤ã§è¡¨ç¾ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:133
msgid ""
"If the code point is >= 128, it's turned into a sequence of two, three, or "
"four bytes, where each byte of the sequence is between 128 and 255."
msgstr ""
"ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒ 128 ä»¥ä¸Šã®å ´åˆã€128 ã‹ã‚‰ 255 ã¾ã§ã®ãƒã‚¤ãƒˆã‹ã‚‰ãªã‚‹ã€2ã€3 ã¾ãŸ"
"ã¯ 4 ãƒã‚¤ãƒˆã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¤‰æ›ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:136
msgid "UTF-8 has several convenient properties:"
msgstr "UTF-8 ã¯ã„ãã¤ã‹ã®ä¾¿åˆ©ãªæ€§è³ªã‚’æŒã£ã¦ã„ã¾ã™:"

#: ../../howto/unicode.rst:138
msgid "It can handle any Unicode code point."
msgstr "ä»»æ„ã® Unicode ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ‰±ã†ã“ã¨ãŒã§ãã‚‹ã€‚"

#: ../../howto/unicode.rst:139
msgid ""
"A Unicode string is turned into a sequence of bytes that contains embedded "
"zero bytes only where they represent the null character (U+0000). This means "
"that UTF-8 strings can be processed by C functions such as ``strcpy()`` and "
"sent through protocols that can't handle zero bytes for anything other than "
"end-of-string markers."
msgstr ""

#: ../../howto/unicode.rst:144
msgid "A string of ASCII text is also valid UTF-8 text."
msgstr "ASCII ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡å­—åˆ—ã¯ UTF-8 ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ã‚‚æœ‰åŠ¹ã§ã™ã€‚"

#: ../../howto/unicode.rst:145
msgid ""
"UTF-8 is fairly compact; the majority of commonly used characters can be "
"represented with one or two bytes."
msgstr ""
"UTF-8 ã¯ã‹ãªã‚Šã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã§ã™; ã‚ˆãä½¿ã‚ã‚Œã¦ã„ã‚‹æ–‡å­—ã®å¤§å¤šæ•°ã¯ 1 ãƒã‚¤ãƒˆã‹ 2 ãƒ"
"ã‚¤ãƒˆã§è¡¨ç¾ã§ãã¾ã™ã€‚"

#: ../../howto/unicode.rst:147
msgid ""
"If bytes are corrupted or lost, it's possible to determine the start of the "
"next UTF-8-encoded code point and resynchronize.  It's also unlikely that "
"random 8-bit data will look like valid UTF-8."
msgstr ""
"ãƒã‚¤ãƒˆãŒæ¬ è½ã—ãŸã‚Šã€å¤±ã‚ã‚ŒãŸå ´åˆã€æ¬¡ã® UTF-8 ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"
"ã®é–‹å§‹ã‚’æ±ºå®šã—ã€å†åŒæœŸã™ã‚‹ã“ã¨ãŒã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚åŒæ§˜ã®ç†ç”±ã§ãƒ©ãƒ³ãƒ€ãƒ "
"ãª 8-bit ãƒ‡ãƒ¼ã‚¿ã¯æ­£å½“ãª UTF-8 ã¨ã¿ãªã•ã‚Œã«ãããªã£ã¦ã„ã¾ã™ã€‚"

#: ../../howto/unicode.rst:150
msgid ""
"UTF-8 is a byte oriented encoding. The encoding specifies that each "
"character is represented by a specific sequence of one or more bytes. This "
"avoids the byte-ordering issues that can occur with integer and word "
"oriented encodings, like UTF-16 and UTF-32, where the sequence of bytes "
"varies depending on the hardware on which the string was encoded."
msgstr ""

#: ../../howto/unicode.rst:158 ../../howto/unicode.rst:514
#: ../../howto/unicode.rst:735
msgid "References"
msgstr "å‚è€ƒè³‡æ–™"

#: ../../howto/unicode.rst:160
msgid ""
"The `Unicode Consortium site <https://www.unicode.org>`_ has character "
"charts, a glossary, and PDF versions of the Unicode specification.  Be "
"prepared for some difficult reading.  `A chronology <https://www.unicode.org/"
"history/>`_ of the origin and development of Unicode is also available on "
"the site."
msgstr ""
"`Unicode ã‚³ãƒ³ã‚½ãƒ¼ã‚·ã‚¢ãƒ ã®ã‚µã‚¤ãƒˆ <https://www.unicode.org>`_ ã«ã¯æ–‡å­—ã®å›³è¡¨ã€"
"ç”¨èªè¾å…¸ã€PDF ç‰ˆã® Unicode ä»•æ§˜ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œèª­ã‚€ã®ã¯ãã‚Œãªã‚Šã«é›£ã—ã„ã®ã§è¦š"
"æ‚Ÿã—ã¦ãã ã•ã„ã€‚Unicode ã®èµ·æºã¨ç™ºå±•ã® `å¹´è¡¨ <https://www.unicode.org/"
"history/>`_ ã‚‚ã‚µã‚¤ãƒˆã«ã‚ã‚Šã¾ã™ã€‚"

#: ../../howto/unicode.rst:165
msgid ""
"On the Computerphile Youtube channel, Tom Scott briefly `discusses the "
"history of Unicode and UTF-8 <https://www.youtube.com/watch?v=MijmeoH9LT4>`_ "
"(9 minutes 36 seconds)."
msgstr ""

#: ../../howto/unicode.rst:169
msgid ""
"To help understand the standard, Jukka Korpela has written `an introductory "
"guide <https://jkorpela.fi/unicode/guide.html>`_ to reading the Unicode "
"character tables."
msgstr ""
"æ¨™æº–ã‚’ç†è§£ã™ã‚‹åŠ©ã‘ã«ã™ã‚‹ãŸã‚ã«ã€Jukka Korpela ãŒ Unicode æ–‡å­—è¡¨ã‚’èª­ã‚€ãŸã‚ã® `"
"å…¥é–€ã‚¬ã‚¤ãƒ‰ <https://jkorpela.fi/unicode/guide.html>`_ ã‚’æ›¸ã„ã¦ã„ã¾ã™ã€‚"

#: ../../howto/unicode.rst:173
msgid ""
"Another `good introductory article <https://www.joelonsoftware."
"com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-"
"positively-must-know-about-unicode-and-character-sets-no-excuses/>`_ was "
"written by Joel Spolsky. If this introduction didn't make things clear to "
"you, you should try reading this alternate article before continuing."
msgstr ""

#: ../../howto/unicode.rst:178
msgid ""
"Wikipedia entries are often helpful; see the entries for \"`character "
"encoding <https://en.wikipedia.org/wiki/Character_encoding>`_\" and `UTF-8 "
"<https://en.wikipedia.org/wiki/UTF-8>`_, for example."
msgstr ""
"Wikipedia ã®è¨˜äº‹ã¯ã—ã°ã—ã°å½¹ã«ç«‹ã¡ã¾ã™; ä¾‹ãˆã°ã€\"`character encoding "
"<https://en.wikipedia.org/wiki/Character_encoding>`_\" ã‚„ `UTF-8 <https://en."
"wikipedia.org/wiki/UTF-8>`_ ã®è¨˜äº‹ã‚’èª­ã‚“ã§ã¿ã¦ãã ã•ã„ã€‚"

#: ../../howto/unicode.rst:184
msgid "Python's Unicode Support"
msgstr "Python ã® Unicode ã‚µãƒãƒ¼ãƒˆ"

#: ../../howto/unicode.rst:186
msgid ""
"Now that you've learned the rudiments of Unicode, we can look at Python's "
"Unicode features."
msgstr ""
"ã“ã“ã¾ã§ã§ Unicode ã®åŸºç¤ã‚’å­¦ã³ã¾ã—ãŸã€ã“ã“ã‹ã‚‰ Python ã® Unicode æ©Ÿèƒ½ã«è§¦ã‚Œ"
"ã¾ã™ã€‚"

#: ../../howto/unicode.rst:190
msgid "The String Type"
msgstr "æ–‡å­—åˆ—å‹"

#: ../../howto/unicode.rst:192
msgid ""
"Since Python 3.0, the language's :class:`str` type contains Unicode "
"characters, meaning any string created using ``\"unicode rocks!\"``, "
"``'unicode rocks!'``, or the triple-quoted string syntax is stored as "
"Unicode."
msgstr ""

#: ../../howto/unicode.rst:196
msgid ""
"The default encoding for Python source code is UTF-8, so you can simply "
"include a Unicode character in a string literal::"
msgstr ""
"Python ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ UTF-8 ãªã®ã§ã€æ–‡å­—åˆ—ãƒªãƒ†ãƒ©"
"ãƒ«ã®ä¸­ã« Unicode æ–‡å­—ã‚’ãã®ã¾ã¾å«ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™::"

#: ../../howto/unicode.rst:199
msgid ""
"try:\n"
"    with open('/tmp/input.txt', 'r') as f:\n"
"        ...\n"
"except OSError:\n"
"    # 'File not found' error message.\n"
"    print(\"Fichier non trouvÃ©\")"
msgstr ""

#: ../../howto/unicode.rst:206
msgid ""
"Side note: Python 3 also supports using Unicode characters in identifiers::"
msgstr "è¿½è¨˜: Python3 ã¯ Unicode æ–‡å­—ã‚’ä½¿ã£ãŸè­˜åˆ¥å­ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™::"

#: ../../howto/unicode.rst:208
msgid ""
"rÃ©pertoire = \"/tmp/records.log\"\n"
"with open(rÃ©pertoire, \"w\") as f:\n"
"    f.write(\"test\\n\")"
msgstr ""

#: ../../howto/unicode.rst:212
msgid ""
"If you can't enter a particular character in your editor or want to keep the "
"source code ASCII-only for some reason, you can also use escape sequences in "
"string literals. (Depending on your system, you may see the actual capital-"
"delta glyph instead of a \\u escape.) ::"
msgstr ""
"ã‚¨ãƒ‡ã‚£ã‚¿ã§ã‚ã‚‹ç‰¹å®šã®æ–‡å­—ãŒå…¥åŠ›ã§ããªã‹ã£ãŸã‚Šã€ã¨ã‚ã‚‹ç†ç”±ã§ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ "
"ASCII ã®ã¿ã«ä¿ã¡ãŸã„å ´åˆã¯ã€æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒä½¿ãˆã¾ã™ã€‚"
"(ä½¿ã£ã¦ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦ã¯ã€\\u ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸæ–‡å­—åˆ—ã§ã¯ãªãã€å®Ÿç‰©ã®å¤§æ–‡"
"å­—ã®ãƒ©ãƒ ãƒ€ã®ã‚°ãƒªãƒ•ãŒè¦‹ãˆã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚)::"

#: ../../howto/unicode.rst:217
msgid ""
">>> \"\\N{GREEK CAPITAL LETTER DELTA}\"  # Using the character name\n"
"'\\u0394'\n"
">>> \"\\u0394\"                          # Using a 16-bit hex value\n"
"'\\u0394'\n"
">>> \"\\U00000394\"                      # Using a 32-bit hex value\n"
"'\\u0394'"
msgstr ""

#: ../../howto/unicode.rst:224
msgid ""
"In addition, one can create a string using the :func:`~bytes.decode` method "
"of :class:`bytes`.  This method takes an *encoding* argument, such as "
"``UTF-8``, and optionally an *errors* argument."
msgstr ""
"åŠ ãˆã¦ã€ :class:`bytes` ã‚¯ãƒ©ã‚¹ã® :func:`~bytes.decode` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã£ã¦æ–‡å­—åˆ—"
"ã‚’ä½œã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ ``UTF-8`` ã®ã‚ˆã†ãªå€¤ã‚’ *encoding* å¼•æ•°ã«"
"å–ã‚Šã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ *errors* å¼•æ•°ã‚’å–ã‚Šã¾ã™ã€‚"

#: ../../howto/unicode.rst:228
msgid ""
"The *errors* argument specifies the response when the input string can't be "
"converted according to the encoding's rules.  Legal values for this argument "
"are ``'strict'`` (raise a :exc:`UnicodeDecodeError` exception), "
"``'replace'`` (use ``U+FFFD``, ``REPLACEMENT CHARACTER``), ``'ignore'`` "
"(just leave the character out of the Unicode result), or "
"``'backslashreplace'`` (inserts a ``\\xNN`` escape sequence). The following "
"examples show the differences::"
msgstr ""
"*errors* å¼•æ•°ã¯ã€å…¥åŠ›æ–‡å­—åˆ—ã«å¯¾ã—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ãŸå¤‰æ›ãŒã§ããª"
"ã‹ã£ãŸã¨ãã®å¯¾å¿œæ–¹æ³•ã‚’æŒ‡å®šã—ã¾ã™ã€‚ã“ã®å¼•æ•°ã«ä½¿ãˆã‚‹å€¤ã¯ ``'strict'`` (:exc:"
"`UnicodeDecodeError` ã‚’é€å‡ºã™ã‚‹)ã€ ``'replace'`` (``REPLACEMENT CHARACTER`` "
"ã§ã‚ã‚‹ ``U+FFFD`` ã‚’ä½¿ã†)ã€ ``'ignore'`` (çµæœã¨ãªã‚‹ Unicode ã‹ã‚‰å˜ã«æ–‡å­—ã‚’é™¤"
"ã) ã€``'backslashreplace'`` (ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ ``\\xNN`` ã‚’æŒ¿å…¥ã™ã‚‹) ã§"
"ã™ã€‚æ¬¡ã®ä¾‹ã¯ã“ã‚Œã‚‰ã®é•ã„ã‚’ç¤ºã—ã¦ã„ã¾ã™::"

#: ../../howto/unicode.rst:236
msgid ""
">>> b'\\x80abc'.decode(\"utf-8\", \"strict\")  \n"
"Traceback (most recent call last):\n"
"    ...\n"
"UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0:\n"
"  invalid start byte\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"replace\")\n"
"'\\ufffdabc'\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"backslashreplace\")\n"
"'\\\\x80abc'\n"
">>> b'\\x80abc'.decode(\"utf-8\", \"ignore\")\n"
"'abc'"
msgstr ""

#: ../../howto/unicode.rst:248
msgid ""
"Encodings are specified as strings containing the encoding's name.  Python "
"comes with roughly 100 different encodings; see the Python Library Reference "
"at :ref:`standard-encodings` for a list.  Some encodings have multiple "
"names; for example, ``'latin-1'``, ``'iso_8859_1'`` and ``'8859``' are all "
"synonyms for the same encoding."
msgstr ""
"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®åå‰ã‚’å«ã‚“ã æ–‡å­—åˆ—ã§æŒ‡å®šã•ã‚Œã¾ã™ã€‚ "
"Python ã¯ãŠã‚ˆã 100 ã®ç•°ãªã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã™; ä¸€è¦§ã¯ Python "
"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã® :ref:`standard-encodings` ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚ã„ãã¤"
"ã‹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯è¤‡æ•°ã®åå‰ã‚’æŒã£ã¦ã„ã¾ã™; ä¾‹ãˆã°ã€ ``'latin-1'`` ã¨ "
"``'iso_8859_1'`` ã¨ ``'8859'`` ã¯å…¨ã¦åŒã˜ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®åˆ¥åã§ã™ã€‚"

#: ../../howto/unicode.rst:254
msgid ""
"One-character Unicode strings can also be created with the :func:`chr` built-"
"in function, which takes integers and returns a Unicode string of length 1 "
"that contains the corresponding code point.  The reverse operation is the "
"built-in :func:`ord` function that takes a one-character Unicode string and "
"returns the code point value::"
msgstr ""
"Unicode æ–‡å­—åˆ—ã®ä¸€ã¤ã®æ–‡å­—ã¯ :func:`chr` çµ„ã¿è¾¼ã¿é–¢æ•°ã§ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾"
"ã™ã€ã“ã®é–¢æ•°ã¯æ•´æ•°ã‚’å¼•æ•°ã«ã¨ã‚Šã€å¯¾å¿œã™ã‚‹ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å«ã‚€é•·ã•1ã® Unicode "
"æ–‡å­—åˆ—ã‚’è¿”ã—ã¾ã™ã€‚é€†ã®æ“ä½œã¯ :func:`ord` çµ„ã¿è¾¼ã¿é–¢æ•°ã§ã™ã€ã“ã®é–¢æ•°ã¯ä¸€æ–‡å­—"
"ã® Unicode æ–‡å­—åˆ—ã‚’å¼•æ•°ã«ã¨ã‚Šã€ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆå€¤ã‚’è¿”ã—ã¾ã™::"

#: ../../howto/unicode.rst:260
msgid ""
">>> chr(57344)\n"
"'\\ue000'\n"
">>> ord('\\ue000')\n"
"57344"
msgstr ""

#: ../../howto/unicode.rst:266
msgid "Converting to Bytes"
msgstr "ãƒã‚¤ãƒˆåˆ—ã¸ã®å¤‰æ›"

#: ../../howto/unicode.rst:268
msgid ""
"The opposite method of :meth:`bytes.decode` is :meth:`str.encode`, which "
"returns a :class:`bytes` representation of the Unicode string, encoded in "
"the requested *encoding*."
msgstr ""
":meth:`bytes.decode` ã¨ã¯å‡¦ç†ãŒé€†å‘ãã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒ :meth:`str.encode` ã§ã™ã€‚ã“"
"ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€ Unicode æ–‡å­—åˆ—ã‚’æŒ‡å®šã•ã‚ŒãŸ *encoding* ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã€ :"
"class:`bytes` ã«ã‚ˆã‚‹è¡¨ç¾ã§è¿”ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:272
msgid ""
"The *errors* parameter is the same as the parameter of the :meth:`~bytes."
"decode` method but supports a few more possible handlers. As well as "
"``'strict'``, ``'ignore'``, and ``'replace'`` (which in this case inserts a "
"question mark instead of the unencodable character), there is also "
"``'xmlcharrefreplace'`` (inserts an XML character reference), "
"``backslashreplace`` (inserts a ``\\uNNNN`` escape sequence) and "
"``namereplace`` (inserts a ``\\N{...}`` escape sequence)."
msgstr ""
"*errors* å¼•æ•°ã¯ :meth:`~bytes.decode` ãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨åŒã˜ã‚‚ã®ã§ã™ãŒã€"
"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒãƒ³ãƒ‰ãƒ©ã®æ•°ãŒã‚‚ã†å°‘ã—å¤šã„ã§ã™ã€‚\n"
"``'strict'`` ã€ ``'ignore'`` ã€ ``'replace'`` (ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã§ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§"
"ããªã‹ã£ãŸæ–‡å­—ã®ä»£ã‚ã‚Šã«ç–‘å•ç¬¦ã‚’æŒ¿å…¥ã™ã‚‹) ã®ä»–ã«ã€ ``'xmlcharrefreplace'`` "
"(XML æ–‡å­—å‚ç…§ã‚’æŒ¿å…¥ã™ã‚‹) ã¨ ``backslashreplace`` (ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ "
"``\\nNNNN`` ã‚’æŒ¿å…¥ã™ã‚‹)ã€ ``namereplace`` (ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ ``\\N{...}`` "
"ã‚’æŒ¿å…¥ã™ã‚‹) ãŒã‚ã‚Šã¾ã™ã€‚"

#: ../../howto/unicode.rst:280
msgid "The following example shows the different results::"
msgstr "æ¬¡ã®ä¾‹ã§ã¯ã€ãã‚Œãã‚Œã®ç•°ãªã‚‹å‡¦ç†çµæœãŒç¤ºã•ã‚Œã¦ã„ã¾ã™::"

#: ../../howto/unicode.rst:282
msgid ""
">>> u = chr(40960) + 'abcd' + chr(1972)\n"
">>> u.encode('utf-8')\n"
"b'\\xea\\x80\\x80abcd\\xde\\xb4'\n"
">>> u.encode('ascii')  \n"
"Traceback (most recent call last):\n"
"    ...\n"
"UnicodeEncodeError: 'ascii' codec can't encode character '\\ua000' in\n"
"  position 0: ordinal not in range(128)\n"
">>> u.encode('ascii', 'ignore')\n"
"b'abcd'\n"
">>> u.encode('ascii', 'replace')\n"
"b'?abcd?'\n"
">>> u.encode('ascii', 'xmlcharrefreplace')\n"
"b'&#40960;abcd&#1972;'\n"
">>> u.encode('ascii', 'backslashreplace')\n"
"b'\\\\ua000abcd\\\\u07b4'\n"
">>> u.encode('ascii', 'namereplace')\n"
"b'\\\\N{YI SYLLABLE IT}abcd\\\\u07b4'"
msgstr ""

#: ../../howto/unicode.rst:301
msgid ""
"The low-level routines for registering and accessing the available encodings "
"are found in the :mod:`codecs` module.  Implementing new encodings also "
"requires understanding the :mod:`codecs` module. However, the encoding and "
"decoding functions returned by this module are usually more low-level than "
"is comfortable, and writing new encodings is a specialized task, so the "
"module won't be covered in this HOWTO."
msgstr ""
"åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç™»éŒ²ã—ãŸã‚Šã€ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸã‚Šã™ã‚‹ä½ãƒ¬ãƒ™ãƒ«ã®ãƒ«ãƒ¼ãƒãƒ³"
"ã¯ :mod:`codecs` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã‚ã‚Šã¾ã™ã€‚æ–°ã—ã„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Ÿè£…ã™ã‚‹ã«"
"ã¯ã€ :mod:`codecs` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç†è§£ã—ã¦ã„ã‚‹ã“ã¨ã‚‚å¿…è¦ã«ãªã‚Šã¾ã™ã€‚ã—ã‹ã—ã€ã“ã®"
"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚„ãƒ‡ã‚³ãƒ¼ãƒ‰ã®é–¢æ•°ã¯ã€ä½¿ã„å‹æ‰‹ãŒè‰¯ã„ã¨ã„ã†ã‚ˆã‚Šä½ãƒ¬ãƒ™ãƒ«ãª"
"é–¢æ•°ã§ã€æ–°ã—ã„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ›¸ãã®ã¯ç‰¹æ®Šãªä½œæ¥­ãªã®ã§ã€ã“ã® HOWTO ã§ã¯æ‰±ã‚"
"ãªã„ã“ã¨ã«ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:310
msgid "Unicode Literals in Python Source Code"
msgstr "Python ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å†…ã® Unicode ãƒªãƒ†ãƒ©ãƒ«"

#: ../../howto/unicode.rst:312
msgid ""
"In Python source code, specific Unicode code points can be written using the "
"``\\u`` escape sequence, which is followed by four hex digits giving the "
"code point.  The ``\\U`` escape sequence is similar, but expects eight hex "
"digits, not four::"
msgstr ""
"Python ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å†…ã§ã¯ã€ç‰¹å®šã®ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ "
"``\\u`` ã‚’ä½¿ã„ã€ç¶šã‘ã¦ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’4æ¡ã®16é€²æ•°ã‚’æ›¸ãã¾ã™ã€‚ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±"
"ãƒ³ã‚¹ ``\\U`` ã‚‚åŒæ§˜ã§ã™ã€ãŸã ã—4æ¡ã§ã¯ãªã8æ¡ã®16é€²æ•°ã‚’ä½¿ã„ã¾ã™::"

#: ../../howto/unicode.rst:317
msgid ""
">>> s = \"a\\xac\\u1234\\u20ac\\U00008000\"\n"
"... #     ^^^^ two-digit hex escape\n"
"... #         ^^^^^^ four-digit Unicode escape\n"
"... #                     ^^^^^^^^^^ eight-digit Unicode escape\n"
">>> [ord(c) for c in s]\n"
"[97, 172, 4660, 8364, 32768]"
msgstr ""

#: ../../howto/unicode.rst:324
msgid ""
"Using escape sequences for code points greater than 127 is fine in small "
"doses, but becomes an annoyance if you're using many accented characters, as "
"you would in a program with messages in French or some other accent-using "
"language.  You can also assemble strings using the :func:`chr` built-in "
"function, but this is even more tedious."
msgstr ""
"127 ã‚ˆã‚Šå¤§ãã„ã‚³ãƒ¼ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«å¯¾ã—ã¦ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½¿ã†ã®ã¯ã€ã‚¨ã‚¹ã‚±ãƒ¼"
"ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒã‚ã¾ã‚Šå¤šããªã„ã†ã¡ã¯æœ‰åŠ¹ã§ã™ãŒã€ãƒ•ãƒ©ãƒ³ã‚¹èªç­‰ã®ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã‚’ä½¿ã†"
"è¨€èªã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚ˆã†ãªå¤šãã®ã‚¢ã‚¯ã‚»ãƒ³ãƒˆæ–‡å­—ã‚’ä½¿ã†å ´åˆã«ã¯é‚ªé­”ã«ãªã‚Šã¾ã™ã€‚æ–‡"
"å­—ã‚’ :func:`chr` çµ„ã¿è¾¼ã¿é–¢æ•°ã‚’ä½¿ã£ã¦çµ„ã¿ä¸Šã’ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ãŒã€ãã‚Œã¯ã•ã‚‰ã«"
"é•·ããªã£ã¦ã—ã¾ã†ã§ã—ã‚‡ã†ã€‚"

#: ../../howto/unicode.rst:330
msgid ""
"Ideally, you'd want to be able to write literals in your language's natural "
"encoding.  You could then edit Python source code with your favorite editor "
"which would display the accented characters naturally, and have the right "
"characters used at runtime."
msgstr ""
"ç†æƒ³çš„ã«ã¯ã‚ãªãŸã®è¨€èªã®è‡ªç„¶ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ãƒªãƒ†ãƒ©ãƒ«ã‚’æ›¸ãã“ã¨ã§ã—ã‚‡ã†ã€‚"
"ãã†ãªã‚Œã°ã€Python ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ã‚¢ã‚¯ã‚»ãƒ³ãƒˆä»˜ãã®æ–‡å­—ã‚’è‡ªç„¶ã«è¡¨ç¤ºã™ã‚‹ãŠæ°—ã«"
"å…¥ã‚Šã®ã‚¨ãƒ‡ã‚£ã‚¿ã§ç·¨é›†ã—ã€å®Ÿè¡Œæ™‚ã«æ­£ã—ã„æ–‡å­—ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚"

#: ../../howto/unicode.rst:335
msgid ""
"Python supports writing source code in UTF-8 by default, but you can use "
"almost any encoding if you declare the encoding being used.  This is done by "
"including a special comment as either the first or second line of the source "
"file::"
msgstr ""
"Python ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ UTF-8 ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã“ã¨ãŒã§ãã¾ã™ã€ãŸã ã—ã©ã®ã‚¨"
"ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ã†ã‹ã‚’å®£è¨€ã™ã‚Œã°ã»ã¨ã‚“ã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ãˆã¾ã™ã€‚ãã‚Œ"
"ã¯ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¡Œç›®ã‚„äºŒè¡Œç›®ã«ç‰¹åˆ¥ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’å«ã‚ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã§ãã¾"
"ã™::"

#: ../../howto/unicode.rst:339
msgid ""
"#!/usr/bin/env python\n"
"# -*- coding: latin-1 -*-\n"
"\n"
"u = 'abcdÃ©'\n"
"print(ord(u[-1]))"
msgstr ""

#: ../../howto/unicode.rst:345
msgid ""
"The syntax is inspired by Emacs's notation for specifying variables local to "
"a file.  Emacs supports many different variables, but Python only supports "
"'coding'.  The ``-*-`` symbols indicate to Emacs that the comment is "
"special; they have no significance to Python but are a convention.  Python "
"looks for ``coding: name`` or ``coding=name`` in the comment."
msgstr ""
"ã“ã®æ§‹æ–‡ã¯ Emacs ã®ãƒ•ã‚¡ã‚¤ãƒ«å›ºæœ‰ã®å¤‰æ•°ã‚’æŒ‡å®šã™ã‚‹è¡¨è¨˜ã‹ã‚‰å½±éŸ¿ã‚’å—ã‘ã¦ã„ã¾ã™ã€‚"
"Emacs ã¯æ§˜ã€…ãªå¤‰æ•°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ãŒã€Python ãŒã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã®ã¯ "
"'coding' ã®ã¿ã§ã™ã€‚ ``-*-`` ã®è¨˜æ³•ã¯ Emacs ã«å¯¾ã—ã¦ã‚³ãƒ¡ãƒ³ãƒˆãŒç‰¹åˆ¥ã§ã‚ã‚‹ã“ã¨ã‚’"
"ç¤ºã—ã¾ã™ã€‚ã“ã‚Œã¯ Python ã«ã¨ã£ã¦æ„å‘³ã¯ã‚ã‚Šã¾ã›ã‚“ãŒæ…£ç¿’ã§ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚ "
"Python ã¯ã‚³ãƒ¡ãƒ³ãƒˆä¸­ã« ``coding: name`` ã¾ãŸã¯ ``coding=name`` ã‚’æ¢ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:351
msgid ""
"If you don't include such a comment, the default encoding used will be UTF-8 "
"as already mentioned.  See also :pep:`263` for more information."
msgstr ""
"ã“ã®ã‚ˆã†ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’å«ã‚“ã§ã„ãªã„å ´åˆã€ã™ã§ã«è¿°ã¹ãŸé€šã‚Šã€ä½¿ã‚ã‚Œã‚‹ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨"
"ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ UTF-8 ã«ãªã‚Šã¾ã™ã€‚ã‚ˆã‚Šè©³ã—ã„æƒ…å ±ã¯ :pep:`263` ã‚’å‚ç…§ã—ã¦ãã "
"ã•ã„ã€‚"

#: ../../howto/unicode.rst:356
msgid "Unicode Properties"
msgstr "Unicode ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£"

#: ../../howto/unicode.rst:358
msgid ""
"The Unicode specification includes a database of information about code "
"points.  For each defined code point, the information includes the "
"character's name, its category, the numeric value if applicable (for "
"characters representing numeric concepts such as the Roman numerals, "
"fractions such as one-third and four-fifths, etc.).  There are also display-"
"related properties, such as how to use the code point in bidirectional text."
msgstr ""

#: ../../howto/unicode.rst:366
msgid ""
"The following program displays some information about several characters, "
"and prints the numeric value of one particular character::"
msgstr ""
"ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã„ãã¤ã‹ã®æ–‡å­—ã«å¯¾ã™ã‚‹æƒ…å ±ã‚’è¡¨ç¤ºã—ã€ç‰¹å®šã®æ–‡å­—ã®æ•°å€¤ã‚’å°å­—"
"ã—ã¾ã™::"

#: ../../howto/unicode.rst:369
msgid ""
"import unicodedata\n"
"\n"
"u = chr(233) + chr(0x0bf2) + chr(3972) + chr(6000) + chr(13231)\n"
"\n"
"for i, c in enumerate(u):\n"
"    print(i, '%04x' % ord(c), unicodedata.category(c), end=\" \")\n"
"    print(unicodedata.name(c))\n"
"\n"
"# Get numeric value of second character\n"
"print(unicodedata.numeric(u[1]))"
msgstr ""

#: ../../howto/unicode.rst:380
msgid "When run, this prints:"
msgstr "å®Ÿè¡Œã™ã‚‹ã¨ã€ã“ã®ã‚ˆã†ã«å‡ºåŠ›ã•ã‚Œã¾ã™::"

#: ../../howto/unicode.rst:382
msgid ""
"0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE\n"
"1 0bf2 No TAMIL NUMBER ONE THOUSAND\n"
"2 0f84 Mn TIBETAN MARK HALANTA\n"
"3 1770 Lo TAGBANWA LETTER SA\n"
"4 33af So SQUARE RAD OVER S SQUARED\n"
"1000.0"
msgstr ""

#: ../../howto/unicode.rst:391
msgid ""
"The category codes are abbreviations describing the nature of the character. "
"These are grouped into categories such as \"Letter\", \"Number\", "
"\"Punctuation\", or \"Symbol\", which in turn are broken up into "
"subcategories.  To take the codes from the above output, ``'Ll'`` means "
"'Letter, lowercase', ``'No'`` means \"Number, other\", ``'Mn'`` is \"Mark, "
"nonspacing\", and ``'So'`` is \"Symbol, other\".  See `the General Category "
"Values section of the Unicode Character Database documentation <https://www."
"unicode.org/reports/tr44/#General_Category_Values>`_ for a list of category "
"codes."
msgstr ""
"ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚³ãƒ¼ãƒ‰ã¯æ–‡å­—ã®æ€§è³ªã‚’ç•¥è¨˜ã§è¡¨ã—ãŸã‚‚ã®ã§ã™ã€‚ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚³ãƒ¼ãƒ‰ã¯ "
"\"Letter\"ã€\"Number\"ã€\"Punctuation\"ã€\"Symbol\" ãªã©ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«åˆ†é¡ã•"
"ã‚Œã€ã•ã‚‰ã«ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ç´°åˆ†åŒ–ã•ã‚Œã¾ã™ã€‚ä¸Šè¨˜ã®å‡ºåŠ›ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’æ‹¾ã†ã¨ã€"
"``'Ll'`` ã¯ 'Letter, lowercase'ã€``'No'`` ã¯ \"Number, other\"ã€``'Mn'`` ã¯ "
"\"Mark, nonspacing\"ã€``'So'`` ã¯ \"Symbol, other\" ã‚’æ„å‘³ã—ã¦ã„ã¾ã™ã€‚ã‚«ãƒ†ã‚´"
"ãƒªãƒ¼ã‚³ãƒ¼ãƒ‰ã®ä¸€è¦§ã¯ `Unicode Character Database æ–‡æ›¸ã® General Category "
"Values ç¯€ <https://www.unicode.org/reports/tr44/#General_Category_Values>`_ "
"ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"

#: ../../howto/unicode.rst:402
msgid "Comparing Strings"
msgstr ""

#: ../../howto/unicode.rst:404
msgid ""
"Unicode adds some complication to comparing strings, because the same set of "
"characters can be represented by different sequences of code points.  For "
"example, a letter like 'Ãª' can be represented as a single code point U+00EA, "
"or as U+0065 U+0302, which is the code point for 'e' followed by a code "
"point for 'COMBINING CIRCUMFLEX ACCENT'.  These will produce the same output "
"when printed, but one is a string of length 1 and the other is of length 2."
msgstr ""

#: ../../howto/unicode.rst:412
msgid ""
"One tool for a case-insensitive comparison is the :meth:`~str.casefold` "
"string method that converts a string to a case-insensitive form following an "
"algorithm described by the Unicode Standard.  This algorithm has special "
"handling for characters such as the German letter 'ÃŸ' (code point U+00DF), "
"which becomes the pair of lowercase letters 'ss'."
msgstr ""

#: ../../howto/unicode.rst:421
msgid ""
">>> street = 'GÃ¼rzenichstraÃŸe'\n"
">>> street.casefold()\n"
"'gÃ¼rzenichstrasse'"
msgstr ""

#: ../../howto/unicode.rst:425
msgid ""
"A second tool is the :mod:`unicodedata` module's :func:`~unicodedata."
"normalize` function that converts strings to one of several normal forms, "
"where letters followed by a combining character are replaced with single "
"characters.  :func:`~unicodedata.normalize` can be used to perform string "
"comparisons that won't falsely report inequality if two strings use "
"combining characters differently:"
msgstr ""

#: ../../howto/unicode.rst:434
msgid ""
"import unicodedata\n"
"\n"
"def compare_strs(s1, s2):\n"
"    def NFD(s):\n"
"        return unicodedata.normalize('NFD', s)\n"
"\n"
"    return NFD(s1) == NFD(s2)\n"
"\n"
"single_char = 'Ãª'\n"
"multiple_chars = '\\N{LATIN SMALL LETTER E}\\N{COMBINING CIRCUMFLEX "
"ACCENT}'\n"
"print('length of first string=', len(single_char))\n"
"print('length of second string=', len(multiple_chars))\n"
"print(compare_strs(single_char, multiple_chars))"
msgstr ""

#: ../../howto/unicode.rst:448
msgid "When run, this outputs:"
msgstr "å®Ÿè¡Œã™ã‚‹ã¨ã€ã“ã®ã‚ˆã†ã«å‡ºåŠ›ã•ã‚Œã¾ã™:"

#: ../../howto/unicode.rst:450
msgid ""
"$ python compare-strs.py\n"
"length of first string= 1\n"
"length of second string= 2\n"
"True"
msgstr ""

#: ../../howto/unicode.rst:457
msgid ""
"The first argument to the :func:`~unicodedata.normalize` function is a "
"string giving the desired normalization form, which can be one of 'NFC', "
"'NFKC', 'NFD', and 'NFKD'."
msgstr ""

#: ../../howto/unicode.rst:461
msgid "The Unicode Standard also specifies how to do caseless comparisons::"
msgstr ""

#: ../../howto/unicode.rst:463
msgid ""
"import unicodedata\n"
"\n"
"def compare_caseless(s1, s2):\n"
"    def NFD(s):\n"
"        return unicodedata.normalize('NFD', s)\n"
"\n"
"    return NFD(NFD(s1).casefold()) == NFD(NFD(s2).casefold())\n"
"\n"
"# Example usage\n"
"single_char = 'Ãª'\n"
"multiple_chars = '\\N{LATIN CAPITAL LETTER E}\\N{COMBINING CIRCUMFLEX "
"ACCENT}'\n"
"\n"
"print(compare_caseless(single_char, multiple_chars))"
msgstr ""

#: ../../howto/unicode.rst:477
msgid ""
"This will print ``True``.  (Why is :func:`!NFD` invoked twice?  Because "
"there are a few characters that make :meth:`~str.casefold` return a non-"
"normalized string, so the result needs to be normalized again. See section "
"3.13 of the Unicode Standard for a discussion and an example.)"
msgstr ""

#: ../../howto/unicode.rst:484
msgid "Unicode Regular Expressions"
msgstr "Unicode æ­£è¦è¡¨ç¾"

#: ../../howto/unicode.rst:486
msgid ""
"The regular expressions supported by the :mod:`re` module can be provided "
"either as bytes or strings.  Some of the special character sequences such as "
"``\\d`` and ``\\w`` have different meanings depending on whether the pattern "
"is supplied as bytes or a string.  For example, ``\\d`` will match the "
"characters ``[0-9]`` in bytes but in strings will match any character that's "
"in the ``'Nd'`` category."
msgstr ""
":mod:`re` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹æ­£è¦è¡¨ç¾ã¯ãƒã‚¤ãƒˆåˆ—ã‚„æ–‡å­—åˆ—ã¨ã—ã¦ä¸ãˆã‚‰"
"ã‚Œã¾ã™ã€‚ ``\\d`` ã‚„ ``\\w`` ãªã©ã®ã„ãã¤ã‹ã®ç‰¹æ®Šãªæ–‡å­—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¯ã€ãã®ãƒ‘"
"ã‚¿ãƒ¼ãƒ³ãŒãƒã‚¤ãƒˆåˆ—ã¨ã—ã¦ä¸ãˆã‚‰ã‚ŒãŸã®ã‹æ–‡å­—åˆ—ã¨ã—ã¦ä¸ãˆã‚‰ã‚ŒãŸã®ã‹ã«ã‚ˆã£ã¦ã€ç•°ãª"
"ã‚‹æ„å‘³ã‚’æŒã¡ã¾ã™ã€‚ä¾‹ãˆã°ã€ ``\\d`` ã¯ãƒã‚¤ãƒˆåˆ—ã§ã¯ ``[0-9]`` ã®ç¯„å›²ã®æ–‡å­—ã¨ä¸€"
"è‡´ã—ã¾ã™ãŒã€æ–‡å­—åˆ—ã§ã¯ ``'Nd'`` ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ã‚ã‚‹ä»»æ„ã®æ–‡å­—ã¨ä¸€è‡´ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:493
msgid ""
"The string in this example has the number 57 written in both Thai and Arabic "
"numerals::"
msgstr ""
"ã“ã®ä¾‹ã«ã‚ã‚‹æ–‡å­—åˆ—ã«ã¯ã€ã‚¿ã‚¤èªã®æ•°å­—ã¨ã‚¢ãƒ©ãƒ“ã‚¢æ•°å­—ã®ä¸¡æ–¹ã§æ•°å­—ã® 57 ãŒæ›¸ã„ã¦"
"ã‚ã‚Šã¾ã™ã€‚"

#: ../../howto/unicode.rst:496
msgid ""
"import re\n"
"p = re.compile(r'\\d+')\n"
"\n"
"s = \"Over \\u0e55\\u0e57 57 flavours\"\n"
"m = p.search(s)\n"
"print(repr(m.group()))"
msgstr ""

#: ../../howto/unicode.rst:503
msgid ""
"When executed, ``\\d+`` will match the Thai numerals and print them out.  If "
"you supply the :const:`re.ASCII` flag to :func:`~re.compile`, ``\\d+`` will "
"match the substring \"57\" instead."
msgstr ""
"å®Ÿè¡Œã™ã‚‹ã¨ã€ ``\\d+`` ã¯ã‚¿ã‚¤èªã®æ•°å­—ã¨ä¸€è‡´ã—ã€ãã‚Œã‚’å‡ºåŠ›ã—ã¾ã™ã€‚ãƒ•ãƒ©ã‚° :"
"const:`re.ASCII` ã‚’ :func:`~re.compile` ã«æ¸¡ã—ãŸå ´åˆã€ ``\\d+`` ã¯å…ˆç¨‹ã¨ã¯"
"é•ã£ã¦éƒ¨åˆ†æ–‡å­—åˆ— \"57\" ã«ä¸€è‡´ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:507
msgid ""
"Similarly, ``\\w`` matches a wide variety of Unicode characters but only "
"``[a-zA-Z0-9_]`` in bytes or if :const:`re.ASCII` is supplied, and ``\\s`` "
"will match either Unicode whitespace characters or ``[ \\t\\n\\r\\f\\v]``."
msgstr ""
"åŒæ§˜ã«ã€ ``\\w`` ã¯éå¸¸ã«å¤šãã® Unicode æ–‡å­—ã«ä¸€è‡´ã—ã¾ã™ãŒã€ãƒã‚¤ãƒˆåˆ—ã®å ´åˆã‚‚"
"ã—ãã¯ :const:`re.ASCII` ãŒæ¸¡ã•ã‚ŒãŸå ´åˆã¯ ``[a-zA-Z0-9_]`` ã«ã—ã‹ä¸€è‡´ã—ã¾ã›"
"ã‚“ã€‚ ``\\s`` ã¯æ–‡å­—åˆ—ã§ã¯ Unicode ç©ºç™½æ–‡å­—ã«ã€ãƒã‚¤ãƒˆåˆ—ã§ã¯ "
"``[ \\t\\n\\r\\f\\v]`` ã«ä¸€è‡´ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:518
msgid "Some good alternative discussions of Python's Unicode support are:"
msgstr "Python ã® Unicode ã‚µãƒãƒ¼ãƒˆã«ã¤ã„ã¦ã®å‚è€ƒã«ãªã‚‹è­°è«–ã¯ä»¥ä¸‹ã®2ã¤ã§ã™:"

#: ../../howto/unicode.rst:520
msgid ""
"`Processing Text Files in Python 3 <https://python-notes.curiousefficiency."
"org/en/latest/python3/text_file_processing.html>`_, by Nick Coghlan."
msgstr ""
"Nick Coghlan ã«ã‚ˆã‚‹ `Processing Text Files in Python 3 <https://python-notes."
"curiousefficiency.org/en/latest/python3/text_file_processing.html>`_"

#: ../../howto/unicode.rst:521
msgid ""
"`Pragmatic Unicode <https://nedbatchelder.com/text/unipain.html>`_, a PyCon "
"2012 presentation by Ned Batchelder."
msgstr ""
"Ned Batchelder ã«ã‚ˆã‚‹ PyCon 2012 ã§ã®ç™ºè¡¨ `Pragmatic Unicode <https://"
"nedbatchelder.com/text/unipain.html>`_"

#: ../../howto/unicode.rst:523
msgid ""
"The :class:`str` type is described in the Python library reference at :ref:"
"`textseq`."
msgstr ""
":class:`str` å‹ã«ã¤ã„ã¦ã¯ Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã® :ref:`textseq` ã§è§£"
"èª¬ã•ã‚Œã¦ã„ã¾ã™ã€‚"

#: ../../howto/unicode.rst:526
msgid "The documentation for the :mod:`unicodedata` module."
msgstr ":mod:`unicodedata` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¤ã„ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€‚"

#: ../../howto/unicode.rst:528
msgid "The documentation for the :mod:`codecs` module."
msgstr ":mod:`codecs` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã¤ã„ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€‚"

#: ../../howto/unicode.rst:530
msgid ""
"Marc-AndrÃ© Lemburg gave `a presentation titled \"Python and Unicode\" (PDF "
"slides) <https://downloads.egenix.com/python/Unicode-EPC2002-Talk.pdf>`_ at "
"EuroPython 2002.  The slides are an excellent overview of the design of "
"Python 2's Unicode features (where the Unicode string type is called "
"``unicode`` and literals start with ``u``)."
msgstr ""
"Marc-AndrÃ© Lemburg ã¯ EuroPython 2002 ã§ `\"Python and Unicode\" ã¨ã„ã†ã‚¿ã‚¤ãƒˆ"
"ãƒ«ã®ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ (PDF ã‚¹ãƒ©ã‚¤ãƒ‰) <https://downloads.egenix.com/python/"
"Unicode-EPC2002-Talk.pdf>`_ ã‚’è¡Œã„ã¾ã—ãŸã€‚ã“ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã¯ Python 2 ã® Unicode "
"æ©Ÿèƒ½ (Unicode æ–‡å­—åˆ—å‹ãŒ ``unicode`` ã¨å‘¼ã°ã‚Œã€ãƒªãƒ†ãƒ©ãƒ«ã¯ ``u`` ã§å§‹ã¾ã‚Šã¾"
"ã™) ã®è¨­è¨ˆã«ã¤ã„ã¦æ¦‚è¦³ã™ã‚‹ç´ æ™´ã—ã„è³‡æ–™ã§ã™ã€‚"

#: ../../howto/unicode.rst:538
msgid "Reading and Writing Unicode Data"
msgstr "Unicode ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿æ›¸ãã™ã‚‹"

#: ../../howto/unicode.rst:540
msgid ""
"Once you've written some code that works with Unicode data, the next problem "
"is input/output.  How do you get Unicode strings into your program, and how "
"do you convert Unicode into a form suitable for storage or transmission?"
msgstr ""
"ä¸€æ—¦ Unicode ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚³ãƒ¼ãƒ‰ãŒå‹•ä½œã™ã‚‹ã‚ˆã†ã«æ›¸ãçµ‚ãˆãŸã‚‰ã€æ¬¡ã®å•é¡Œã¯å…¥å‡º"
"åŠ›ã§ã™ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ Unicode æ–‡å­—åˆ—ã‚’ã©ã†å—ã‘ã¨ã‚Šã€ã©ã† Unicode ã‚’å¤–éƒ¨è¨˜æ†¶è£…"
"ç½®ã‚„é€å—ä¿¡è£…ç½®ã«é©ã—ãŸå½¢å¼ã«å¤‰æ›ã™ã‚‹ã®ã§ã—ã‚‡ã†?"

#: ../../howto/unicode.rst:544
msgid ""
"It's possible that you may not need to do anything depending on your input "
"sources and output destinations; you should check whether the libraries used "
"in your application support Unicode natively.  XML parsers often return "
"Unicode data, for example.  Many relational databases also support Unicode-"
"valued columns and can return Unicode values from an SQL query."
msgstr ""
"å…¥åŠ›ã‚½ãƒ¼ã‚¹ã¨å‡ºåŠ›å…ˆã«ä¾å­˜ã—ãªã„ã‚ˆã†ãªæ–¹æ³•ã¯å¯èƒ½ã§ã™; ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«åˆ©ç”¨ã•"
"ã‚Œã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒ Unicode ã‚’ãã®ã¾ã¾ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‹ã‚’èª¿ã¹ãªã‘ã‚Œã°ã„ã‘ã¾"
"ã›ã‚“ã€‚ä¾‹ãˆã° XML ãƒ‘ãƒ¼ã‚µãƒ¼ã¯å¤§æŠµ Unicode ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚å¤šãã®ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠ"
"ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚‚ Unicode å€¤ã®å…¥ã£ãŸã‚³ãƒ©ãƒ ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã—ã€ SQL ã®å•ã„"
"åˆã‚ã›ã§ Unicode å€¤ã‚’è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚"

#: ../../howto/unicode.rst:550
msgid ""
"Unicode data is usually converted to a particular encoding before it gets "
"written to disk or sent over a socket.  It's possible to do all the work "
"yourself: open a file, read an 8-bit bytes object from it, and convert the "
"bytes with ``bytes.decode(encoding)``.  However, the manual approach is not "
"recommended."
msgstr ""
"Unicode ã®ãƒ‡ãƒ¼ã‚¿ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã«æ›¸ãè¾¼ã¾ã‚ŒãŸã‚Šã€ã‚½ã‚±ãƒƒãƒˆã‚’ä»‹ã—ã¦é€ä¿¡ã•ã‚ŒãŸã‚Šã™ã‚‹"
"ã«ã‚ãŸã£ã¦ã€é€šå¸¸ã€ç‰¹å®šã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚æ¨å¥¨ã¯ã•ã‚Œã¾ã›ã‚“ãŒã€"
"ã“ã‚Œã‚’æ‰‹å‹•ã§è¡Œã†ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã€8ãƒã‚¤ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’èª­ã¿è¾¼"
"ã¿ã€ãƒã‚¤ãƒˆåˆ—ã‚’ ``bytes.decode(encoding)`` ã§å¤‰æ›ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šå®Ÿç¾ã§ãã¾ã™ã€‚"

#: ../../howto/unicode.rst:555
msgid ""
"One problem is the multi-byte nature of encodings; one Unicode character can "
"be represented by several bytes.  If you want to read the file in arbitrary-"
"sized chunks (say, 1024 or 4096 bytes), you need to write error-handling "
"code to catch the case where only part of the bytes encoding a single "
"Unicode character are read at the end of a chunk.  One solution would be to "
"read the entire file into memory and then perform the decoding, but that "
"prevents you from working with files that are extremely large; if you need "
"to read a 2 GiB file, you need 2 GiB of RAM. (More, really, since for at "
"least a moment you'd need to have both the encoded string and its Unicode "
"version in memory.)"
msgstr ""
"1ã¤ã®å•é¡Œã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒãƒãƒ«ãƒãƒã‚¤ãƒˆã«æ¸¡ã‚‹ã¨ã„ã†æ€§è³ªã§ã™; 1ã¤ã® Unicode "
"æ–‡å­—ã¯ã„ãã¤ã‹ã®ãƒã‚¤ãƒˆã§è¡¨ç¾ã•ã‚Œå¾—ã¾ã™ã€‚ä»»æ„ã®ã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ (ä¾‹ãˆã°ã€1024 "
"ã‚‚ã—ãã¯ 4096 ãƒã‚¤ãƒˆ) ã«ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿ãŸã„å ´åˆã€ã‚ã‚‹1ã¤ã® Unicode "
"æ–‡å­—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸãƒã‚¤ãƒˆåˆ—ã®ä¸€éƒ¨ã ã‘ãŒãƒãƒ£ãƒ³ã‚¯ã®æœ«å°¾ã¾ã§èª­ã¿è¾¼ã¾ã‚ŒãŸã‚±ãƒ¼ã‚¹"
"ã«å¯¾å¿œã™ã‚‹ã€ã‚¨ãƒ©ãƒ¼å‡¦ç†ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚1ã¤ã®è§£æ±ºç­–ã¯ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’"
"ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿ã€ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã™ãŒã€ã“ã†ã—ã¦ã—ã¾ã†ã¨éå¸¸ã«å¤§"
"ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹ã¨ãã®å¦¨ã’ã«ãªã‚Šã¾ã™; 2 GiB ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€å¿…è¦ãŒ"
"ã‚ã‚‹å ´åˆã€2 GiB ã® RAM ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚(å®Ÿéš›ã«ã¯ã€å°‘ãªãã¨ã‚‚ã‚ã‚‹ç¬é–“ã§ã¯ã€"
"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ–‡å­—åˆ—ã¨ Unicode æ–‡å­—åˆ—ã®ä¸¡æ–¹ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿æŒã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸ"
"ã‚ã€ã‚ˆã‚Šå¤šãã®ãƒ¡ãƒ¢ãƒªãŒå¿…è¦ã§ã™ã€‚)"

#: ../../howto/unicode.rst:565
msgid ""
"The solution would be to use the low-level decoding interface to catch the "
"case of partial coding sequences.  The work of implementing this has already "
"been done for you: the built-in :func:`open` function can return a file-like "
"object that assumes the file's contents are in a specified encoding and "
"accepts Unicode parameters for methods such as :meth:`~io.TextIOBase.read` "
"and :meth:`~io.TextIOBase.write`.  This works through :func:`open`\\'s "
"*encoding* and *errors* parameters which are interpreted just like those in :"
"meth:`str.encode` and :meth:`bytes.decode`."
msgstr ""

#: ../../howto/unicode.rst:574
msgid "Reading Unicode from a file is therefore simple::"
msgstr "ãã®ãŸã‚ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ Unicode ã‚’èª­ã‚€ã®ã¯å˜ç´”ã§ã™::"

#: ../../howto/unicode.rst:576
msgid ""
"with open('unicode.txt', encoding='utf-8') as f:\n"
"    for line in f:\n"
"        print(repr(line))"
msgstr ""

#: ../../howto/unicode.rst:580
msgid ""
"It's also possible to open files in update mode, allowing both reading and "
"writing::"
msgstr "èª­ã¿æ›¸ãã®ä¸¡æ–¹ãŒã§ãã‚‹ update ãƒ¢ãƒ¼ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã“ã¨ã‚‚å¯èƒ½ã§ã™::"

#: ../../howto/unicode.rst:583
msgid ""
"with open('test', encoding='utf-8', mode='w+') as f:\n"
"    f.write('\\u4500 blah blah blah\\n')\n"
"    f.seek(0)\n"
"    print(repr(f.readline()[:1]))"
msgstr ""

#: ../../howto/unicode.rst:588
msgid ""
"The Unicode character ``U+FEFF`` is used as a byte-order mark (BOM), and is "
"often written as the first character of a file in order to assist with "
"autodetection of the file's byte ordering.  Some encodings, such as UTF-16, "
"expect a BOM to be present at the start of a file; when such an encoding is "
"used, the BOM will be automatically written as the first character and will "
"be silently dropped when the file is read.  There are variants of these "
"encodings, such as 'utf-16-le' and 'utf-16-be' for little-endian and big-"
"endian encodings, that specify one particular byte ordering and don't skip "
"the BOM."
msgstr ""
"Unicode æ–‡å­— ``U+FEFF`` ã¯ byte-order mark (BOM) ã¨ã—ã¦ä½¿ã‚ã‚Œã€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¤"
"ãƒˆé †ã®è‡ªå‹•åˆ¤å®šã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã«ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€åˆã®æ–‡å­—ã¨ã—ã¦æ›¸ã‹ã‚Œã¾ã™ã€‚UTF-16 "
"ã®ã‚ˆã†ãªã„ãã¤ã‹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã« BOM ãŒã‚ã‚‹ã“ã¨ã‚’è¦æ±‚ã—"
"ã¾ã™; ãã®ã‚ˆã†ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒä½¿ã‚ã‚Œã‚‹ã¨ãã€è‡ªå‹•çš„ã« BOM ãŒæœ€åˆã®æ–‡å­—ã¨ã—"
"ã¦æ›¸ã‹ã‚Œã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã‚€ã¨ãã«æš—é»™ã®å†…ã«å–ã‚Šé™¤ã‹ã‚Œã¾ã™ã€‚ã“ã‚Œã‚‰ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£"
"ãƒ³ã‚°ã«ã¯ã€ãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ (little-endian) ç”¨ã® 'utf-16-le' ã‚„ãƒ“ãƒƒã‚°ã‚¨ãƒ³"
"ãƒ‡ã‚£ã‚¢ãƒ³ (big-endian) ç”¨ã® 'utf-16-be' ã¨ã„ã†ã‚ˆã†ãªå¤‰ç¨®ãŒã‚ã‚Šã€ã“ã‚Œã‚‰ã¯ç‰¹å®šã®"
"1ã¤ã®ãƒã‚¤ãƒˆé †ã‚’æŒ‡å®šã—ã¦ã„ã¦ BOM ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã›ã‚“ã€‚"

#: ../../howto/unicode.rst:597
msgid ""
"In some areas, it is also convention to use a \"BOM\" at the start of UTF-8 "
"encoded files; the name is misleading since UTF-8 is not byte-order "
"dependent. The mark simply announces that the file is encoded in UTF-8.  For "
"reading such files, use the 'utf-8-sig' codec to automatically skip the mark "
"if present."
msgstr ""

#: ../../howto/unicode.rst:604
msgid "Unicode filenames"
msgstr "Unicode ãƒ•ã‚¡ã‚¤ãƒ«å"

#: ../../howto/unicode.rst:606
msgid ""
"Most of the operating systems in common use today support filenames that "
"contain arbitrary Unicode characters.  Usually this is implemented by "
"converting the Unicode string into some encoding that varies depending on "
"the system.  Today Python is converging on using UTF-8: Python on MacOS has "
"used UTF-8 for several versions, and Python 3.6 switched to using UTF-8 on "
"Windows as well.  On Unix systems, there will only be a :term:`filesystem "
"encoding <filesystem encoding and error handler>`. if you've set the "
"``LANG`` or ``LC_CTYPE`` environment variables; if you haven't, the default "
"encoding is again UTF-8."
msgstr ""

#: ../../howto/unicode.rst:616
msgid ""
"The :func:`sys.getfilesystemencoding` function returns the encoding to use "
"on your current system, in case you want to do the encoding manually, but "
"there's not much reason to bother.  When opening a file for reading or "
"writing, you can usually just provide the Unicode string as the filename, "
"and it will be automatically converted to the right encoding for you::"
msgstr ""
":func:`sys.getfilesystemencoding` é–¢æ•°ã¯ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã§åˆ©ç”¨ã™ã‚‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£"
"ãƒ³ã‚°ã‚’è¿”ã—ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ‰‹å‹•ã§è¨­å®šã—ãŸã„å ´åˆåˆ©ç”¨ã—ã¾ã™ã€ãŸã ã—ã‚ã–ã‚ã–"
"ãã†ã™ã‚‹ç©æ¥µçš„ãªç†ç”±ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚èª­ã¿æ›¸ãã®ãŸã‚ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãæ™‚ã«ã¯ã€ãƒ•ã‚¡"
"ã‚¤ãƒ«åã‚’ Unicode æ–‡å­—åˆ—ã¨ã—ã¦æ¸¡ã™ã ã‘ã§æ­£ã—ã„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«è‡ªå‹•çš„ã«å¤‰æ›´ã•"
"ã‚Œã¾ã™::"

#: ../../howto/unicode.rst:622
msgid ""
"filename = 'filename\\u4500abc'\n"
"with open(filename, 'w') as f:\n"
"    f.write('blah\\n')"
msgstr ""

#: ../../howto/unicode.rst:626
msgid ""
"Functions in the :mod:`os` module such as :func:`os.stat` will also accept "
"Unicode filenames."
msgstr ""
":func:`os.stat` ã®ã‚ˆã†ãª :mod:`os` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é–¢æ•°ã‚‚ Unicode ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’"
"å—ã‘ä»˜ã‘ã¾ã™ã€‚"

#: ../../howto/unicode.rst:629
msgid ""
"The :func:`os.listdir` function returns filenames, which raises an issue: "
"should it return the Unicode version of filenames, or should it return bytes "
"containing the encoded versions?  :func:`os.listdir` can do both, depending "
"on whether you provided the directory path as bytes or a Unicode string.  If "
"you pass a Unicode string as the path, filenames will be decoded using the "
"filesystem's encoding and a list of Unicode strings will be returned, while "
"passing a byte path will return the filenames as bytes.  For example, "
"assuming the default :term:`filesystem encoding <filesystem encoding and "
"error handler>` is UTF-8, running the following program::"
msgstr ""

#: ../../howto/unicode.rst:639
msgid ""
"fn = 'filename\\u4500abc'\n"
"f = open(fn, 'w')\n"
"f.close()\n"
"\n"
"import os\n"
"print(os.listdir(b'.'))\n"
"print(os.listdir('.'))"
msgstr ""

#: ../../howto/unicode.rst:647
msgid "will produce the following output:"
msgstr "ä»¥ä¸‹ã®å‡ºåŠ›çµæœãŒç”Ÿæˆã•ã‚Œã¾ã™:"

#: ../../howto/unicode.rst:649
msgid ""
"$ python listdir-test.py\n"
"[b'filename\\xe4\\x94\\x80abc', ...]\n"
"['filename\\u4500abc', ...]"
msgstr ""

#: ../../howto/unicode.rst:655
msgid ""
"The first list contains UTF-8-encoded filenames, and the second list "
"contains the Unicode versions."
msgstr ""
"æœ€åˆã®ãƒªã‚¹ãƒˆã¯ UTF-8 ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’å«ã¿ã€ç¬¬äºŒã®ãƒªã‚¹ãƒˆ"
"ã¯ Unicode ç‰ˆã‚’å«ã‚“ã§ã„ã¾ã™ã€‚"

#: ../../howto/unicode.rst:658
msgid ""
"Note that on most occasions, you should can just stick with using Unicode "
"with these APIs.  The bytes APIs should only be used on systems where "
"undecodable file names can be present; that's pretty much only Unix systems "
"now."
msgstr ""

#: ../../howto/unicode.rst:665
msgid "Tips for Writing Unicode-aware Programs"
msgstr "Unicode å¯¾å¿œã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ããŸã‚ã® Tips"

#: ../../howto/unicode.rst:667
msgid ""
"This section provides some suggestions on writing software that deals with "
"Unicode."
msgstr ""
"ã“ã®ç« ã§ã¯ Unicode ã‚’æ‰±ã†ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ›¸ããŸã‚ã®ã„ãã¤ã‹ã®ææ¡ˆã‚’ç´¹ä»‹ã—ã¾ã™ã€‚"

#: ../../howto/unicode.rst:670
msgid "The most important tip is:"
msgstr "æœ€ã‚‚é‡è¦ãªåŠ©è¨€ã¨ã—ã¦ã¯:"

#: ../../howto/unicode.rst:672
msgid ""
"Software should only work with Unicode strings internally, decoding the "
"input data as soon as possible and encoding the output only at the end."
msgstr ""
"ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¯å†…éƒ¨ã§ã¯ Unicode æ–‡å­—åˆ—ã®ã¿ã‚’åˆ©ç”¨ã—ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã¯ã§ãã‚‹ã ã‘æ—©æœŸ"
"ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã€å‡ºåŠ›ã®ç›´å‰ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã¹ãã§ã™ã€‚"

#: ../../howto/unicode.rst:675
msgid ""
"If you attempt to write processing functions that accept both Unicode and "
"byte strings, you will find your program vulnerable to bugs wherever you "
"combine the two different kinds of strings.  There is no automatic encoding "
"or decoding: if you do e.g. ``str + bytes``, a :exc:`TypeError` will be "
"raised."
msgstr ""

#: ../../howto/unicode.rst:680
msgid ""
"When using data coming from a web browser or some other untrusted source, a "
"common technique is to check for illegal characters in a string before using "
"the string in a generated command line or storing it in a database.  If "
"you're doing this, be careful to check the decoded string, not the encoded "
"bytes data; some encodings may have interesting properties, such as not "
"being bijective or not being fully ASCII-compatible.  This is especially "
"true if the input data also specifies the encoding, since the attacker can "
"then choose a clever way to hide malicious text in the encoded bytestream."
msgstr ""
"web ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰æ¥ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„ãã®ä»–ã®ä¿¡é ¼ã§ããªã„ã¨ã“ã‚ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã™ã‚‹"
"å ´åˆã€ãã‚Œã‚‰ã®æ–‡å­—åˆ—ã‹ã‚‰ç”Ÿæˆã—ãŸã‚³ãƒãƒ³ãƒ‰è¡Œã®å®Ÿè¡Œã‚„ã€ãã‚Œã‚‰ã®æ–‡å­—åˆ—ã‚’ãƒ‡ãƒ¼ã‚¿"
"ãƒ™ãƒ¼ã‚¹ã«è“„ãˆã‚‹å‰ã«æ–‡å­—åˆ—ã®ä¸­ã«ä¸æ­£ãªæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã™ã‚‹ã®ãŒä¸€èˆ¬çš„"
"ã§ã™ã€‚ã‚‚ã—ãã†ã„ã†çŠ¶æ³ã«ãªã£ãŸå ´åˆã«ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã¯ãª"
"ãã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ–‡å­—åˆ—ã®ãƒã‚§ãƒƒã‚¯ã‚’å…¥å¿µã«è¡Œãªã£ã¦ä¸‹ã•ã„; ã„ãã¤ã‹ã®ã‚¨ãƒ³ã‚³ãƒ¼"
"ãƒ‡ã‚£ãƒ³ã‚°ã¯å•é¡Œã¨ãªã‚‹æ€§è³ªã‚’æŒã£ã¦ã„ã¾ã™ã€ä¾‹ãˆã°å…¨å˜å°„ã§ãªã‹ã£ãŸã‚Šã€å®Œå…¨ã« "
"ASCII äº’æ›ã§ãªã„ãªã©ã€‚å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æŒ‡å®šã—ã¦ã„ã‚‹å ´åˆã§ã‚‚ãã†"
"ã—ã¦ä¸‹ã•ã„ã€ãªãœãªã‚‰æ”»æ’ƒè€…ã¯å·§ã¿ã«æ‚ªæ„ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸæ–‡å­—åˆ—ã®ä¸­"
"ã«éš ã™ã“ã¨ãŒã§ãã‚‹ã‹ã‚‰ã§ã™ã€‚"

#: ../../howto/unicode.rst:691
msgid "Converting Between File Encodings"
msgstr "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å¤‰æ›"

#: ../../howto/unicode.rst:693
msgid ""
"The :class:`~codecs.StreamRecoder` class can transparently convert between "
"encodings, taking a stream that returns data in encoding #1 and behaving "
"like a stream returning data in encoding #2."
msgstr ""

#: ../../howto/unicode.rst:697
msgid ""
"For example, if you have an input file *f* that's in Latin-1, you can wrap "
"it with a :class:`~codecs.StreamRecoder` to return bytes encoded in UTF-8::"
msgstr ""

#: ../../howto/unicode.rst:701
msgid ""
"new_f = codecs.StreamRecoder(f,\n"
"    # en/decoder: used by read() to encode its results and\n"
"    # by write() to decode its input.\n"
"    codecs.getencoder('utf-8'), codecs.getdecoder('utf-8'),\n"
"\n"
"    # reader/writer: used to read and write to the stream.\n"
"    codecs.getreader('latin-1'), codecs.getwriter('latin-1') )"
msgstr ""

#: ../../howto/unicode.rst:711
msgid "Files in an Unknown Encoding"
msgstr "ä¸æ˜ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ•ã‚¡ã‚¤ãƒ«"

#: ../../howto/unicode.rst:713
msgid ""
"What can you do if you need to make a change to a file, but don't know the "
"file's encoding?  If you know the encoding is ASCII-compatible and only want "
"to examine or modify the ASCII parts, you can open the file with the "
"``surrogateescape`` error handler::"
msgstr ""

#: ../../howto/unicode.rst:718
msgid ""
"with open(fname, 'r', encoding=\"ascii\", errors=\"surrogateescape\") as f:\n"
"    data = f.read()\n"
"\n"
"# make changes to the string 'data'\n"
"\n"
"with open(fname + '.new', 'w',\n"
"          encoding=\"ascii\", errors=\"surrogateescape\") as f:\n"
"    f.write(data)"
msgstr ""

#: ../../howto/unicode.rst:727
msgid ""
"The ``surrogateescape`` error handler will decode any non-ASCII bytes as "
"code points in a special range running from U+DC80 to U+DCFF.  These code "
"points will then turn back into the same bytes when the ``surrogateescape`` "
"error handler is used to encode the data and write it back out."
msgstr ""

#: ../../howto/unicode.rst:737
msgid ""
"One section of `Mastering Python 3 Input/Output <https://pyvideo.org/"
"video/289/pycon-2010--mastering-python-3-i-o>`_, a PyCon 2010 talk by David "
"Beazley, discusses text processing and binary data handling."
msgstr ""

#: ../../howto/unicode.rst:741
msgid ""
"The `PDF slides for Marc-AndrÃ© Lemburg's presentation \"Writing Unicode-"
"aware Applications in Python\" <https://downloads.egenix.com/python/LSM2005-"
"Developing-Unicode-aware-applications-in-Python.pdf>`_ discuss questions of "
"character encodings as well as how to internationalize and localize an "
"application.  These slides cover Python 2.x only."
msgstr ""
"Marc-AndrÃ© Lemburg ã®ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ \"Writing Unicode-aware Applications "
"in Python\" ã® PDF ã‚¹ãƒ©ã‚¤ãƒ‰ãŒ <https://downloads.egenix.com/python/LSM2005-"
"Developing-Unicode-aware-applications-in-Python.pdf> ã‹ã‚‰å…¥æ‰‹å¯èƒ½ã§ã™ã€ãã—ã¦"
"æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å•é¡Œã¨åŒæ§˜ã«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å›½éš›åŒ–ã‚„ãƒ­ãƒ¼ã‚«ãƒ©ã‚¤ã‚ºã«ã¤"
"ã„ã¦ã‚‚è­°è«–ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã¯ Python 2.x ã®ã¿ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã¾ã™ã€‚"

#: ../../howto/unicode.rst:747
msgid ""
"`The Guts of Unicode in Python <https://pyvideo.org/video/1768/the-guts-of-"
"unicode-in-python>`_ is a PyCon 2013 talk by Benjamin Peterson that "
"discusses the internal Unicode representation in Python 3.3."
msgstr ""

#: ../../howto/unicode.rst:754
msgid "Acknowledgements"
msgstr "è¬è¾"

#: ../../howto/unicode.rst:756
msgid ""
"The initial draft of this document was written by Andrew Kuchling. It has "
"since been revised further by Alexander Belopolsky, Georg Brandl, Andrew "
"Kuchling, and Ezio Melotti."
msgstr ""
"ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æœ€åˆã®è‰ç¨¿ã¯ Andrew Kuchling ã«ã‚ˆã£ã¦æ›¸ã‹ã‚Œã¾ã—ãŸã€‚ãã‚Œã‹ã‚‰"
"ã•ã‚‰ã« Alexander Belopolsky, Georg Brandl, Andrew Kuchling, Ezio Melotti ã‚‰ã§"
"æ”¹è¨‚ãŒé‡ã­ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚"

#: ../../howto/unicode.rst:760
msgid ""
"Thanks to the following people who have noted errors or offered suggestions "
"on this article: Ã‰ric Araujo, Nicholas Bastin, Nick Coghlan, Marius "
"Gedminas, Kent Johnson, Ken Krugler, Marc-AndrÃ© Lemburg, Martin von LÃ¶wis, "
"Terry J. Reedy, Serhiy Storchaka, Eryk Sun, Chad Whitacre, Graham Wideman."
msgstr ""
"ã“ã®è¨˜äº‹ä¸­ã®èª¤ã‚Šã®æŒ‡æ‘˜ã‚„ææ¡ˆã‚’ç”³ã—å‡ºã¦ãã‚ŒãŸä»¥ä¸‹ã®äººã€…ã«æ„Ÿè¬ã—ã¾ã™: Ã‰ric "
"Araujo, Nicholas Bastin, Nick Coghlan, Marius Gedminas, Kent Johnson, Ken "
"Krugler, Marc-AndrÃ© Lemburg, Martin von LÃ¶wis, Terry J. Reedy, Serhiy "
"Storchaka, Eryk Sun, Chad Whitacre, Graham Wideman."
